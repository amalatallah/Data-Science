{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7631ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "x_train = pickle.load(open(\"x_train\", \"rb\"))\n",
    "x_test = pickle.load(open(\"x_test\", \"rb\"))\n",
    "y_train = pickle.load(open(\"y_train\", \"rb\"))\n",
    "y_test = pickle.load(open(\"y_test\", \"rb\"))\n",
    "\n",
    "max_len = 27\n",
    "num_word = 26709"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "309b193d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4344, 2990, 3348, ...,    0,    0,    0],\n",
       "       [2724, 1020, 2725, ...,    0,    0,    0],\n",
       "       [3819, 3349, 2085, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 204, 2367, 1586, ...,    0,    0,    0],\n",
       "       [1661,  751,   14, ...,    0,    0,    0],\n",
       "       [ 796, 1193, 2617, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as  np \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_word)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "train_seq = tokenizer.texts_to_sequences(x_train)\n",
    "train_padded = pad_sequences(train_seq, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "train_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8a50bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6079, 20572,  2534, ...,     0,     0,     0],\n",
       "       [ 3493,   579,  9753, ...,     0,     0,     0],\n",
       "       [  171,   115, 10999, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [   11,  1541,   568, ...,     0,     0,     0],\n",
       "       [  169,  3489,   207, ...,     0,     0,     0],\n",
       "       [ 3200,   767,  2293, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_seq = tokenizer.texts_to_sequences(x_test)\n",
    "test_padded = pad_sequences(test_seq, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "test_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a726cdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paramount pictures proudly shelves latest film\n",
      "[4344, 2990, 3348, 2723, 377, 226]\n"
     ]
    }
   ],
   "source": [
    "print(x_train.iloc[0])\n",
    "print(train_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f25392ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of unique words : 22847\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print(f\"the number of unique words :\", len(word_index))\n",
    "# print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d763a93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ef109523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index[\"film\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c4d5d5",
   "metadata": {},
   "source": [
    "# create the embedding dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "138397ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dic = {}\n",
    "with open(\"glove.twitter.27B.100d.txt\", \"r\", encoding=\"utf8\") as f :\n",
    "    for line in f :\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vectors = np.asarray(values[1:], \"float32\")\n",
    "        embedding_dic[word] = vectors\n",
    "f.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5059f40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((num_word, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < num_word : \n",
    "        emb_vec =embedding_dic.get(word)\n",
    "        if emb_vec is not None : \n",
    "            embedding_matrix[i] = emb_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc6c6e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_dic[\"paramount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd909638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bcbb2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index[\"film\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55c56ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_dic.get(\"film\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d899b378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(embedding_matrix[226] == embedding_dic.get(\"film\")).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8a953df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18696, 27)\n",
      "(18696,)\n"
     ]
    }
   ],
   "source": [
    "print(train_padded.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8b6e6679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense,Embedding\n",
    "from  keras.initializers import Constant\n",
    "\n",
    "model =  Sequential()\n",
    "model.add(Embedding(\n",
    "num_word, 100, embeddings_initializer=Constant(embedding_matrix), input_length=max_len, trainable = False\n",
    "))\n",
    "model.add(LSTM(100, dropout=0.1))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ede554c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "585/585 [==============================] - 14s 19ms/step - loss: 0.5332 - accuracy: 0.7350 - val_loss: 0.8612 - val_accuracy: 0.5315\n",
      "Epoch 2/10\n",
      "585/585 [==============================] - 11s 19ms/step - loss: 0.4623 - accuracy: 0.7812 - val_loss: 0.9402 - val_accuracy: 0.4910\n",
      "Epoch 3/10\n",
      "585/585 [==============================] - 12s 20ms/step - loss: 0.4235 - accuracy: 0.8032 - val_loss: 0.8538 - val_accuracy: 0.5361\n",
      "Epoch 4/10\n",
      "585/585 [==============================] - 11s 20ms/step - loss: 0.3905 - accuracy: 0.8212 - val_loss: 0.9767 - val_accuracy: 0.5044\n",
      "Epoch 5/10\n",
      "585/585 [==============================] - 11s 20ms/step - loss: 0.3613 - accuracy: 0.8388 - val_loss: 1.0082 - val_accuracy: 0.5002\n",
      "Epoch 6/10\n",
      "585/585 [==============================] - 12s 20ms/step - loss: 0.3342 - accuracy: 0.8546 - val_loss: 1.1603 - val_accuracy: 0.5079\n",
      "Epoch 7/10\n",
      "585/585 [==============================] - 12s 20ms/step - loss: 0.3078 - accuracy: 0.8662 - val_loss: 1.1928 - val_accuracy: 0.5066\n",
      "Epoch 8/10\n",
      "585/585 [==============================] - 12s 20ms/step - loss: 0.2833 - accuracy: 0.8801 - val_loss: 1.1808 - val_accuracy: 0.5028\n",
      "Epoch 9/10\n",
      "585/585 [==============================] - 12s 21ms/step - loss: 0.2579 - accuracy: 0.8944 - val_loss: 1.1423 - val_accuracy: 0.5290\n",
      "Epoch 10/10\n",
      "585/585 [==============================] - 12s 21ms/step - loss: 0.2339 - accuracy: 0.9030 - val_loss: 1.3283 - val_accuracy: 0.5120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x225100cd580>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_encode, y_train, validation_data=(test_encode, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd80fdb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e3f786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb31d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdcf9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2416d35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07fd9d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36bcdd35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94b4a148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9d7cff7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46220511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd0ea77d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7931fc70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65ff88a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b0f661da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.tokenize import word_tokenize\n",
    "# import  nltk \n",
    "# def create_corpus(df) : \n",
    "#     corpus = []\n",
    "#     for text in df : \n",
    "#         words = [word.lower() for word in word_tokenize(text)]\n",
    "#         corpus.append(word)\n",
    "#     return corpus\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77e4aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "# a = pd.concat([x_test, x_train], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2748fb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = create_corpus(a)\n",
    "# len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e58cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
